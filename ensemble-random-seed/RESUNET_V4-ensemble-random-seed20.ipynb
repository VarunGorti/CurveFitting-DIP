{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86e31b-2abb-4974-b648-cdb0276e62c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323dacc4-89c5-4f6a-bf59-fb0a197c4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a329bc-9359-4ad5-83b1-1b3cabc37916",
   "metadata": {},
   "source": [
    "# 1. Load the data and get measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd22b3-d54c-4879-885d-d17fe14ded29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/scratch/cluster/vgorti/UTAFSDataNew/new_data\"\n",
    "CHIP_NUM = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3784652d-e58b-49e7-820f-dc9516f381a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "data_dict = utils.grab_chip_data(ROOT_PATH, CHIP_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc32add-f84d-455c-b1f3-a47fa18bf3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0253d82f-fc8a-483c-a5b5-8ea5ffa8c8f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert the raw data matrices to only the unique S-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a71d4-e0ef-48e6-84d9-2d259d01e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_data = utils.matrix_to_sparams(data_dict['vf_matrix'])\n",
    "gt_data = utils.matrix_to_sparams(data_dict['gt_matrix'])\n",
    "y_data = utils.matrix_to_sparams(data_dict['y_matrix'])\n",
    "\n",
    "print(\"VF S-parameters shape: \", vf_data.shape)\n",
    "print(\"GT S-parameters shape: \", gt_data.shape)\n",
    "print(\"Y S-parameters shape: \", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f248a-70f9-4e70-bb4e-bf132e2fe3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_freqs = data_dict['gt_freqs']\n",
    "y_freqs = data_dict['y_freqs']\n",
    "\n",
    "print(\"GT frequencies shape: \", gt_freqs.shape)\n",
    "print(\"Y frequencies shape: \", y_freqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a5998-08b0-4fb1-af81-2bb992c655ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "spacings = gt_freqs[1:] - gt_freqs[:-1]\n",
    "\n",
    "mode_spacing = sp.stats.mode(spacings, keepdims=False)[0]\n",
    "num_mode = len(np.where(spacings==mode_spacing)[0])\n",
    "\n",
    "print(\"First frequency point: \", gt_freqs[0])\n",
    "print(\"Mean frequency spacing: \", np.mean(spacings))\n",
    "print(\"STD frequency spacing: \", np.std(spacings))\n",
    "print(\"Mode frequency spacing: \", mode_spacing)\n",
    "print(\"Number of samples with non-equal spacing: \", len(gt_freqs) - num_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2bc461-a793-49b9-86f6-b98ab7ca43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE THIS IS EXPERIMENTAL!!!\n",
    "if gt_freqs[0] == 0:\n",
    "    gt_freqs = gt_freqs[1:]\n",
    "    gt_data = gt_data[:, :, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a8d4c-66f0-41b2-97bc-5514687818d4",
   "metadata": {},
   "source": [
    "## Make some variables we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4738913-b30b-47af-a422-d4f5f076998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FREQS = gt_data.shape[-1]\n",
    "N_SPARAMS = gt_data.shape[0]  \n",
    "\n",
    "print(\"N_FREQS: \", N_FREQS)\n",
    "print(\"N_SPARAMS: \", N_SPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbfcae-4c18-4257-a1f4-022e1d7b1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(gt_data).view(-1, N_FREQS).unsqueeze(0).to(device)\n",
    "\n",
    "print(\"x shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc954d9-8743-418c-9f21-26c1c6a1052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mag = utils.sparams_to_mag(x)\n",
    "\n",
    "print(\"x_mag shape: \", x_mag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a03c8e-cf12-4c5e-aca6-b3db5b8bd3a2",
   "metadata": {},
   "source": [
    "## Plot some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff78a259-32bf-409a-a9ae-716460744a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(N_SPARAMS):\n",
    "    plt.plot(gt_freqs, x_mag[0, i].cpu(), label=str(i))\n",
    "if N_SPARAMS <= 10:\n",
    "    plt.legend()\n",
    "plt.title(\"Ground Truth Magnitude Spectrum\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b2ee7-20da-467f-b00f-41b53ccb3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(N_SPARAMS):\n",
    "    plt.plot(gt_freqs, x[0,2*i].cpu(), label=str(i)+\" Re\")\n",
    "    plt.plot(gt_freqs, x[0,2*i+1].cpu(), label=str(i)+\" Im\")\n",
    "if N_SPARAMS <= 10:\n",
    "    plt.legend()\n",
    "plt.title(\"Ground Truth Complex Representation\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50dd8c2-6e31-4994-b80b-1a29ed5caca5",
   "metadata": {},
   "source": [
    "## Grab Some Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1cc89-bb70-40df-991c-4a82b04833b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_TYPE = \"equal\" #[random, equal, forecast, full, log, sqrt]\n",
    "# M = int(0.10 * N_FREQS)\n",
    "M = 62\n",
    "\n",
    "kept_inds, missing_inds = utils.get_inds(PROBLEM_TYPE, N_FREQS, M)\n",
    "\n",
    "M = len(kept_inds) #re-define in case kept_inds is off by 1 or something\n",
    "\n",
    "print(\"Number of Ground Truth Frequency Points: \", N_FREQS)\n",
    "print(\"Number of Measurements: \", M)\n",
    "print(\"Undersampling Ratio: \", M/N_FREQS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026d9a6-1445-4608-b76c-13eba2f71860",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.clone(x)[:, :, kept_inds]\n",
    "y_freqs = gt_freqs[kept_inds]\n",
    "\n",
    "print(\"y shape: \", y.shape)\n",
    "print(\"y_freqs shape: \", y_freqs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead318c-5913-467a-959f-0e69157a35c8",
   "metadata": {},
   "source": [
    "# 2. Network Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05083810-dc41-42af-8dbb-1ba7a65f2ebd",
   "metadata": {},
   "source": [
    "## Define network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2bccf0-f3c8-40aa-a78e-12c3aa73a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "NZ = y.shape[1]\n",
    "\n",
    "NUM_LAYERS = int(np.ceil(np.log2(N_FREQS))) - 4\n",
    "\n",
    "if NZ < 64:\n",
    "    BASE_NGF = 2 ** (int(np.ceil(np.log2(NZ))) + 1) #second power of two after NZ \n",
    "elif NZ < 128:\n",
    "    BASE_NGF = 2 ** int(np.ceil(np.log2(NZ))) #next highest power of 2\n",
    "else:\n",
    "    BASE_NGF = NZ\n",
    "\n",
    "NGF = [BASE_NGF] * NUM_LAYERS\n",
    "\n",
    "BS = y.shape[0]\n",
    "NC = y.shape[1]\n",
    "\n",
    "KERNEL_SIZE = 3\n",
    "USE_SKIP = False\n",
    "CAUSAL_PASSIVE = True\n",
    "OPTIMIZE_Z = False\n",
    "USE_SGLD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46b6ec-ae3e-4b8c-8d8a-13417c150144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NZ: \", str(NZ))\n",
    "print(\"NUM_LAYERS: \", str(NUM_LAYERS))\n",
    "print(\"BASE NGF: \", str(BASE_NGF))\n",
    "print(\"NGF: \", str(NGF))\n",
    "print(\"BS: \", BS)\n",
    "print(\"NC: \", NC)\n",
    "print(\"KERNEL_SIZE: \", KERNEL_SIZE)\n",
    "print(\"USE_SKIP: \", USE_SKIP)\n",
    "print(\"CAUSAL_PASSIVE: \", CAUSAL_PASSIVE)\n",
    "print(\"OPTIMIZE_Z: \", OPTIMIZE_Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c01cf7-a114-4ff0-8a22-486438aecc8d",
   "metadata": {},
   "source": [
    "## Init and check dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a23d73-3395-4a95-80c5-0bba6699deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RES_UNET\n",
    "\n",
    "ENSEMBLE_SIZE = 5\n",
    "\n",
    "ensemble = [ RES_UNET(bs=BS,\n",
    "               nz=NZ,\n",
    "               ngf=NGF,\n",
    "               output_size=N_FREQS,\n",
    "               nc=NC,\n",
    "               optimize_z=OPTIMIZE_Z,\n",
    "               kernel_size=KERNEL_SIZE,\n",
    "               num_layers=NUM_LAYERS,\n",
    "               use_skip=USE_SKIP,\n",
    "               causal_passive=CAUSAL_PASSIVE,\n",
    "               p_dropout=0\n",
    "               ) for i in range(ENSEMBLE_SIZE) ] \n",
    "for net in ensemble:\n",
    "    net = net.to(device)\n",
    "\n",
    "# Choose one network to visualize the results\n",
    "net = ensemble[ENSEMBLE_SIZE // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6cac17-464c-4ab9-8bfa-aa781db29b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = net.forward_with_z()\n",
    "\n",
    "print(\"Net output shape: \", test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b3a98-89b8-471b-9246-408941f7960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"TOTAL PARAMS: \", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32c8d5-8633-45bc-bfe2-fe2296a7a9ac",
   "metadata": {},
   "source": [
    "# 3. Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb31a1-36f2-417b-b06b-b3d3c7077bd9",
   "metadata": {},
   "source": [
    "## Define training parameters, losses, and track stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704585c-e8f5-4ba6-ad3f-74122338a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-4\n",
    "NUM_ITER = 20000\n",
    "NUM_BURN_ITER = NUM_ITER * 0 # 0.2\n",
    "SAMPLE_EVERY = 40\n",
    "\n",
    "ACTIVE_ITER_RATIO = 0.1\n",
    "SAMPLE_LAST_N = NUM_ITER * ACTIVE_ITER_RATIO\n",
    "\n",
    "# TODO: maybe come back to this?\n",
    "# TOTAL_ITER = NUM_ITER + 0.1 * NUM_ACTIVE * NUM_ITER\n",
    "\n",
    "REG_HYPERPARAM = 1.0\n",
    "NOISY_INPUT = True\n",
    "USE_SGLD = False\n",
    "\n",
    "optims = [torch.optim.Adam(ensemble[i].parameters(), lr=LR) for i in range(ENSEMBLE_SIZE)]\n",
    "\n",
    "def get_lr(optim):\n",
    "    for g in optim.param_groups:\n",
    "        return g['lr']\n",
    "    \n",
    "def set_lr(optim, lr):\n",
    "    for g in optim.param_groups:\n",
    "        g['lr'] = lr\n",
    "\n",
    "ensemble_outputs = [None for i in range(ENSEMBLE_SIZE)]\n",
    "ensemble_train_losses = [None for i in range(ENSEMBLE_SIZE)]\n",
    "ensemble_train_errors = [None for i in range(ENSEMBLE_SIZE)]\n",
    "ensemble_train_regs = [None for i in range(ENSEMBLE_SIZE)]\n",
    "ensemble_test_mses = [None for i in range(ENSEMBLE_SIZE)]\n",
    "ensemble_test_maes = [None for i in range(ENSEMBLE_SIZE)]\n",
    "\n",
    "is_initial_fit = True\n",
    "tic = time.time()\n",
    "net.train()\n",
    "\n",
    "for j, net in enumerate(ensemble):\n",
    "\n",
    "    START_NOISE_LEVEL = CUR_NOISE_LEVEL = 1.0\n",
    "    END_NOISE_LEVEL = 0.001\n",
    "    NOISE_DECAY_FACTOR = (END_NOISE_LEVEL / START_NOISE_LEVEL)**(1 / NUM_ITER) \n",
    "\n",
    "    START_LR = LR\n",
    "    END_LR = 1e-5\n",
    "    LR_DECAY_FACTOR = 1 # (END_LR / START_LR)**(1 / NUM_ITER)\n",
    "\n",
    "    net = net.train()\n",
    "    optim = optims[j]\n",
    "\n",
    "    # Update the criterion to reflect the new point we have sampled\n",
    "    criterion = utils.Measurement_MSE_Loss(kept_inds=kept_inds, per_param=False, reduction=\"sum\")\n",
    "    criterion = criterion.to(device)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=LR_DECAY_FACTOR)\n",
    "\n",
    "    if REG_HYPERPARAM > 0:\n",
    "        regularizer = utils.Smoothing_Loss(per_param=False, reduction=\"sum\")\n",
    "        regularizer = regularizer.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    train_errors = []\n",
    "    if REG_HYPERPARAM > 0:\n",
    "        train_regs = []\n",
    "\n",
    "    test_mses = []\n",
    "    test_maes = []\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    for i in range(int(NUM_ITER)):\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        if NOISY_INPUT:\n",
    "            out = net.forward_with_z(CUR_NOISE_LEVEL)\n",
    "            CUR_NOISE_LEVEL *= NOISE_DECAY_FACTOR\n",
    "        else:\n",
    "            out = net.forward_with_z()\n",
    "        \n",
    "        train_error = criterion(out, y) \n",
    "        if REG_HYPERPARAM > 0:\n",
    "            train_reg = REG_HYPERPARAM * regularizer(out)\n",
    "            train_loss = train_error + train_reg\n",
    "        else:\n",
    "            train_loss = train_error\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Log the standard metrics across different numbers of samples given\n",
    "            train_losses.append(train_loss.item())\n",
    "            train_errors.append(train_error.item())\n",
    "            if REG_HYPERPARAM > 0:\n",
    "                train_regs.append(train_reg.item())\n",
    "            \n",
    "            test_mse = nn.MSELoss()(out, x)\n",
    "            test_mses.append(test_mse.item())\n",
    "            \n",
    "            test_mae = nn.L1Loss()(out, x)\n",
    "            test_maes.append(test_mae.item())\n",
    "\n",
    "            if (i+1)%1000 == 0 or i == 0:\n",
    "                toc = time.time()\n",
    "                print(\"ITER \", str(i))\n",
    "                print(\"TIME: \", str(toc - tic))\n",
    "                if NOISY_INPUT:\n",
    "                    print(\"NOISE LEVEL: \", CUR_NOISE_LEVEL)\n",
    "                print()\n",
    "\n",
    "    ensemble_outputs[j] = out\n",
    "    ensemble_train_losses[j] = train_losses\n",
    "    ensemble_train_errors[j] = train_errors\n",
    "    ensemble_train_regs[j] = train_regs\n",
    "    ensemble_test_mses[j] = test_mses\n",
    "    ensemble_test_maes[j] = test_maes \n",
    "\n",
    "    def find_max_variance(outputs, pickRandom=False):\n",
    "        # Outputs of shape [NUM_OUTPUTS, 20, 1000]\n",
    "\n",
    "        # Call np.var with dim = 0 to get shape [20, 1000]\n",
    "        var_output = torch.var(outputs, dim=0)\n",
    "\n",
    "        # Sum to go to [1000]\n",
    "        var_output = torch.sum(var_output, dim=0)\n",
    "\n",
    "        if pickRandom:\n",
    "            while True:\n",
    "                rand_idx = random.randint(0, len(var_output) - 1)\n",
    "                if rand_idx not in kept_inds:\n",
    "                    return rand_idx\n",
    "\n",
    "        _, idxs = torch.topk(var_output, len(var_output))\n",
    "\n",
    "        for idx in idxs:\n",
    "            if idx.item() not in kept_inds:\n",
    "                return idx.item()\n",
    "        return -1\n",
    "    \n",
    "    print(\"TIME: \", str(toc - tic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_FORWARD_PASSES = 100\n",
    "# sums_forward_pass_outputs = torch.Tensor(np.zeros(shape=test_out.shape, dtype=np.float32))\n",
    "# sums_squared_forward_pass_outputs = torch.Tensor(np.zeros(shape=test_out.shape, dtype=np.float32))\n",
    "# for i in range(NUM_FORWARD_PASSES):\n",
    "#     sums_forward_pass_outputs += net.forward_with_z().cpu()\n",
    "#     sums_squared_forward_pass_outputs += torch.square(net.forward_with_z()).cpu()\n",
    "\n",
    "# mean_forward_pass_outputs = sums_forward_pass_outputs / NUM_FORWARD_PASSES\n",
    "# std_forward_pass_outputs = torch.sqrt(((NUM_FORWARD_PASSES * sums_squared_forward_pass_outputs) - (sums_forward_pass_outputs * sums_forward_pass_outputs)) / (NUM_FORWARD_PASSES * (NUM_FORWARD_PASSES - 1)))\n",
    "\n",
    "# ensemble_outputs = np.mean(ensemble_outputs, axis=0)\n",
    "\n",
    "# Grab all the tensors in the list and stack them into a single tensor of shape\n",
    "# (ENSEMBLE SIZE, 1, S_PARAMS, FREQS)\n",
    "ensemble_outputs_stacked = torch.stack(ensemble_outputs)\n",
    "ensemble_train_losses_stacked = np.stack(ensemble_train_losses)\n",
    "ensemble_train_errors_stacked = np.stack(ensemble_train_errors)\n",
    "ensemble_test_maes_stacked = np.stack(ensemble_test_maes)\n",
    "ensemble_test_mses_stacked = np.stack(ensemble_test_mses)\n",
    "\n",
    "# Then, get the mean and variance of the actual output shape\n",
    "# (1, S_PARAMS, FREQS)\n",
    "out = torch.mean(ensemble_outputs_stacked, dim=0)\n",
    "var_out = torch.var(ensemble_outputs_stacked, dim=0)\n",
    "\n",
    "# Finally, get the means of all the training metrics\n",
    "train_losses = np.mean(ensemble_train_losses_stacked, axis=0)\n",
    "train_errors = np.mean(ensemble_train_errors_stacked, axis=0)\n",
    "test_maes = np.mean(ensemble_test_maes_stacked, axis=0)\n",
    "test_mses = np.mean(ensemble_test_mses_stacked, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# print(ensemble_outputs)\n",
    "# print(len(ensemble_outputs))\n",
    "# print(len(ensemble_train_losses[0]))\n",
    "# print(len(ensemble_train_errors[0]))\n",
    "# print(len(ensemble_test_maes[0]))\n",
    "# print(len(ensemble_test_mses[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba6f99-e745-42a2-80c9-b7e629340c5e",
   "metadata": {},
   "source": [
    "## Plot metrics and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ad178-c355-4c6b-99df-4e8fe82fce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"TRAIN LOSS\")\n",
    "plt.ylim(0., train_losses[max_idx])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_errors)\n",
    "plt.title(\"TRAIN ERRORS\")\n",
    "plt.ylim(0., train_errors[max_idx])\n",
    "plt.show()\n",
    "\n",
    "if REG_HYPERPARAM > 0:\n",
    "    plt.figure()\n",
    "    plt.plot(train_regs)\n",
    "    plt.title(\"TRAIN REGS\")\n",
    "    plt.ylim(0., train_regs[max_idx])\n",
    "    plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_mses, color='r')\n",
    "plt.title(\"TEST MSE\")\n",
    "plt.ylim(0., test_mses[max_idx])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_maes, color='g')\n",
    "plt.title(\"TEST MAE\")\n",
    "plt.ylim(0, test_maes[max_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367ae0b-4043-4205-ac58-26bbd44086e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Test MSE: \", test_mses[-1])\n",
    "print(\"Best Test MSE: \", np.min(test_mses))\n",
    "print(\"Best Test MSE Iteration: \", np.argmin(test_mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the VF Solution and use it as input to network\n",
    "import VF.vectorfit\n",
    "import os\n",
    "\n",
    "LENGTH = len(gt_freqs)\n",
    "\n",
    "cn = str(CHIP_NUM) if CHIP_NUM > 9 else \"0\" + str(CHIP_NUM)\n",
    "fname = os.path.join(ROOT_PATH, \"case\"+cn)\n",
    "\n",
    "children = os.listdir(fname)\n",
    "children = [f for f in children if cn + \".s\" in f]\n",
    "\n",
    "final_path = os.path.join(fname, children[0])\n",
    "\n",
    "print(final_path)\n",
    "\n",
    "fitter = VF.vectorfit.VectorFitter(final_path)\n",
    "fit1 = fitter.vector_fit(\"VF Result\", y_freqs) \n",
    "vf_output = fit1.fitted_network.s\n",
    "print(vf_output.shape)\n",
    "print(vf_output.dtype)\n",
    "vf_data = np.stack((vf_output.real, vf_output.imag), axis=-1)\n",
    "vf_data = utils.matrix_to_sparams(vf_data)\n",
    "vf_data = torch.tensor(vf_data).view(1, -1, LENGTH)\n",
    "vf_data = vf_data.to(device)\n",
    "print(vf_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09868fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make neworks from DIP, Interp, and Observations\n",
    "DIP_OUT_MATRIX = utils.sparams_to_matrix(out)\n",
    "VF_MATRIX = utils.sparams_to_matrix(vf_data)\n",
    "Y_MATRIX = utils.sparams_to_matrix(y)\n",
    "\n",
    "print(DIP_OUT_MATRIX.shape)\n",
    "print(VF_MATRIX.shape)\n",
    "print(Y_MATRIX.shape)\n",
    "\n",
    "DIP_net = utils.matrix_to_network(DIP_OUT_MATRIX, gt_freqs, \"DIP Recon With \"+str(M)+\" Samples for Chip \"+str(CHIP_NUM))\n",
    "VF_net = utils.matrix_to_network(VF_MATRIX, gt_freqs, \"Vector Fit With \"+str(M)+\" Samples for Chip \"+str(CHIP_NUM))\n",
    "Y_net = utils.matrix_to_network(Y_MATRIX, y_freqs, \"Observations for Chip \"+str(CHIP_NUM))\n",
    "\n",
    "DIP_FINAL_OUT = np.stack((DIP_net.s.real, DIP_net.s.imag), axis=-1)\n",
    "VF_FINAL_OUT = np.stack((VF_net.s.real, VF_net.s.imag), axis=-1)\n",
    "\n",
    "print(DIP_FINAL_OUT.shape)\n",
    "print(VF_FINAL_OUT.shape)\n",
    "\n",
    "dip_data = utils.matrix_to_sparams(DIP_FINAL_OUT)\n",
    "vf_data_mat = utils.matrix_to_sparams(VF_FINAL_OUT)\n",
    "\n",
    "print(dip_data.shape)\n",
    "print(vf_data_mat.shape)\n",
    "print(dip_data.dtype)\n",
    "print(vf_data_mat.dtype)\n",
    "\n",
    "## Compare DIP, VF, and Interp\n",
    "import skimage.metrics\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "psnr_ours = psnr(gt_data, dip_data)\n",
    "psnr_vf = psnr(gt_data, vf_data_mat)\n",
    "print(\"DIP PSNR:      \", psnr_ours)\n",
    "print(\"VF PSNR:       \", psnr_vf)\n",
    "\n",
    "print(\"Mean DIP MSE: \", test_mses[-1])\n",
    "print(\"VF MSE:        \", nn.MSELoss()(vf_data, x).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bcf18-0d7c-4af3-8143-f46fccbf40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dip_errors = x.detach().cpu() - out.detach().cpu()\n",
    "print(gt_freqs.shape)\n",
    "print(out.shape)\n",
    "print(dip_errors.shape)\n",
    "print(y.shape)\n",
    "\n",
    "std_out = torch.sqrt(var_out)\n",
    "\n",
    "print(out.shape)\n",
    "print(vf_data.shape)\n",
    "\n",
    "fig, axes = plt.subplots(5,1, figsize=(24, 30))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the ground truth\n",
    "for i in range(N_SPARAMS):\n",
    "    axes[0].plot(gt_freqs, x[0,2*i].cpu(), label=str(i)+\" re\")\n",
    "    axes[0].plot(gt_freqs, x[0,2*i+1].cpu(), label=str(i)+\" im\")\n",
    "axes[0].set_title(\"Ground Truth\")\n",
    "axes[0].set_ylim(-1,1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[0].legend(loc='upper right')\n",
    "\n",
    "# Plot the vector fit output\n",
    "for i in range(N_SPARAMS):\n",
    "    axes[1].plot(gt_freqs, vf_data[0,2*i].detach().cpu(), label=str(i)+\" re\")\n",
    "    axes[1].plot(gt_freqs, vf_data[0,2*i+1].detach().cpu(), label=str(i)+\" im\")\n",
    "axes[1].set_title(\"VF Output\")\n",
    "axes[1].set_ylim(-1,1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[1].legend(loc='upper right')\n",
    "\n",
    "# DIP Output, can toggle scatter and/or error bars\n",
    "for i in range(N_SPARAMS):\n",
    "\n",
    "    axes[2].plot(gt_freqs, out[0,2*i].detach().cpu(), label=str(i)+\" re\")\n",
    "    axes[2].plot(gt_freqs, out[0,2*i+1].detach().cpu(), label=str(i)+\" im\")\n",
    "    axes[2].fill_between(gt_freqs, out[0,2*i].detach().cpu() - 2 * std_out[0,2*i].detach().cpu(), out[0,2*i].detach().cpu() + 2 * std_out[0,2*i].detach().cpu())\n",
    "    axes[2].fill_between(gt_freqs, out[0,2*i+1].detach().cpu() - 2 * std_out[0,2*i+1].detach().cpu(), out[0,2*i+1].detach().cpu() + 2 * std_out[0,2*i+1].detach().cpu())\n",
    "\n",
    "    axes[2].scatter(gt_freqs[kept_inds], y[0,2*i].cpu(), color='black')\n",
    "    axes[2].scatter(gt_freqs[kept_inds], y[0,2*i+1].cpu(), color='black')\n",
    "axes[2].set_title(\"DIP Output\")\n",
    "axes[2].set_ylim(-1,1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[2].legend(loc='upper right')\n",
    "\n",
    "# DIP Errors\n",
    "for i in range(N_SPARAMS):\n",
    "    axes[3].plot(gt_freqs, torch.abs(dip_errors[0,2*i]).detach().cpu(), label=str(i)+\" re\")\n",
    "    axes[3].plot(gt_freqs, torch.abs(dip_errors[0,2*i+1]).detach().cpu(), label=str(i)+\" im\")\n",
    "axes[3].set_title(\"DIP Errors\")\n",
    "axes[3].set_ylim(-1,1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[3].legend(loc='upper right')\n",
    "\n",
    "# DIP Variances\n",
    "for i in range(N_SPARAMS):\n",
    "    axes[4].plot(gt_freqs, std_out[0,2*i].detach().cpu(), label=str(i)+\" re\")\n",
    "    axes[4].plot(gt_freqs, std_out[0,2*i+1].detach().cpu(), label=str(i)+\" im\")\n",
    "axes[4].set_title(\"DIP Variances\")\n",
    "axes[4].set_ylim(-0.1,0.1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[4].legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985f909-3429-48d3-8503-a4265dd4a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mag = utils.sparams_to_mag(out)\n",
    "dip_errors_mag = x_mag - out_mag \n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(N_SPARAMS):\n",
    "    axes[0].plot(gt_freqs, x_mag[0,i].cpu(), label=str(i))\n",
    "axes[0].set_title(\"Ground Truth Magnitude Spectrum\")\n",
    "axes[0].set_ylim(0,1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[0].legend()\n",
    "\n",
    "for i in range(N_SPARAMS):\n",
    "    axes[1].plot(gt_freqs, out_mag[0,i].detach().cpu(), label=str(i))\n",
    "axes[1].set_title(\"DIP Output Magnitude Spectrum\")\n",
    "axes[1].set_ylim(0,1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[1].legend()\n",
    "    \n",
    "for i in range(N_SPARAMS):\n",
    "    axes[2].plot(gt_freqs, dip_errors[0,i].detach().cpu(), label=str(i))\n",
    "axes[2].set_title(\"DIP Errors Magnitude Spectrum\")\n",
    "axes[2].set_ylim(-1,1)\n",
    "if N_SPARAMS <= 10:\n",
    "    axes[2].legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc086162",
   "metadata": {},
   "source": [
    "### Now calculate the PSNR between the DIP output variances and the true error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5333d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dip_errors.shape)\n",
    "print(var_out.shape)\n",
    "\n",
    "error_psnr = psnr(np.asarray(torch.abs(dip_errors).detach().cpu()), np.asarray(std_out.detach().cpu()), data_range=2)\n",
    "print(error_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0c6a85f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.15553526951742\n"
     ]
    }
   ],
   "source": [
    "print(error_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13208b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f09d14efeb1af5055b7ef4d9adfb3d40e0c1b7736018dd0842f2bb12003322f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
