{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8f8fcf-9288-4be8-beca-74680f9172eb",
   "metadata": {},
   "source": [
    "# Set all seeds and Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07274489-269b-435a-93b0-72c814fdf623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 2022\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eafef3-f73f-495e-adad-796514a083bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38119b-63e9-45c7-b0a2-019442caa14f",
   "metadata": {},
   "source": [
    "# Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8ad5e-458c-49e5-80c8-50167efff34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfad5d1-72cf-4f91-b7c6-c08da2dfb80f",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e0098-e7b8-41a1-b06d-b54adfa19494",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3 # learning rate\n",
    "NUM_ITER = 10000 # number iterations\n",
    "\n",
    "NZ = 2 # input seed dimension\n",
    "NGF = 16 # number of filters per layer\n",
    "\n",
    "BS = 1 #batch size\n",
    "NC = 2 # number of channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63ff04-1334-46ae-8363-f485905c9e5e",
   "metadata": {},
   "source": [
    "# Grab the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f5ca4-3766-484b-9865-ac0936033bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = torch.load(\"/scratch/04703/sravula/UTAFSDataNew/FREQ_VALS.pt\")\n",
    "x_raw = torch.load(\"/scratch/04703/sravula/UTAFSDataNew/X_RAW.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b28b1-3398-4cc2-b66a-22932a2c4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_labels))\n",
    "print(x_labels[0].shape)\n",
    "\n",
    "print(len(x_raw))\n",
    "print(x_raw[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f016fa-6b4c-4a90-8aeb-609494517d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_arr = [torch.min(t).item() for t in x_raw]\n",
    "max_arr = [torch.max(t).item() for t in x_raw]\n",
    "\n",
    "print(\"MIN VAL: \", np.min(min_arr))\n",
    "print(\"MAX VAL: \", np.max(max_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c184da78-e984-4566-a264-9c45f00259ec",
   "metadata": {},
   "source": [
    "## Looks like there's no need to normalize the data further...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13038a10-df74-4453-a429-8562973c07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_series(data, sample_num, chip_num, num_chan):\n",
    "    \"\"\"\n",
    "    Grabs the Real or (Real, Im) series for a single sample and a single chip.\n",
    "    Output shape is (1, num_chan, L)\n",
    "    \"\"\"\n",
    "    x = data[sample_num][:, chip_num, :] #(LEN, 2)\n",
    "    \n",
    "    if num_chan == 1:\n",
    "        x = x[:, 0].unsqueeze(1) #(LEN, 1)\n",
    "    \n",
    "    x = x.unsqueeze(0) #(1, LEN, 1/2)\n",
    "    x = x.permute(0, 2, 1) #(1, 1/2, LEN)\n",
    "    \n",
    "    return x\n",
    "\n",
    "SAMPLE_IDX = 100\n",
    "CHIP_IDX = 5\n",
    "\n",
    "x = get_single_series(x_raw, SAMPLE_IDX, CHIP_IDX, NC)\n",
    "\n",
    "#NOTE TRYING THIS: DELETE LATER\n",
    "# x = (x - torch.min(x)) / (torch.max(x) - torch.min(x))\n",
    "# x = 2 * x - 1\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c7ad2-0b29-4274-bb97-0ce184d1d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inds(problem_type, length, num_kept_samples):\n",
    "    \"\"\"Given a number of samples to keep and a problem type, returns indices to keep from a list\"\"\"\n",
    "    if problem_type==\"random\":\n",
    "        kept_inds = np.random.choice(length, num_kept_samples, replace=False)\n",
    "    elif problem_type==\"equal\":\n",
    "        kept_inds = np.arange(0, length, (length // num_kept_samples))\n",
    "    elif problem_type==\"forecast\":\n",
    "        kept_inds = np.arange(0, num_kept_samples)\n",
    "    elif problem_type==\"full\":\n",
    "        kept_inds = np.arange(0, length)\n",
    "    else:\n",
    "        raise NotImplementedError(\"THIS PROBLEM TYPE IS UNSUPPORTED\")\n",
    "    \n",
    "    missing_inds = np.array([t for t in range(length) if t not in kept_inds])\n",
    "    \n",
    "    return np.sort(kept_inds), np.sort(missing_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e169a-4ac7-499b-9ca1-7a4c6830e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_TYPE = \"equal\" #[random, equal, forecast, full]\n",
    "LENGTH = x.shape[-1]\n",
    "M = 100\n",
    "\n",
    "kept_inds, missing_inds = get_inds(PROBLEM_TYPE, LENGTH, M)\n",
    "M = len(kept_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f4cff-4e83-4d8a-a87f-94309213f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LENGTH)\n",
    "print(M)\n",
    "print(len(kept_inds))\n",
    "print(len(missing_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036076a5-dfe0-4797-a15f-0761743d2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.clone(x)[:, :, kept_inds]\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb6dac-43ed-4a64-b2ed-1ab07844e332",
   "metadata": {},
   "source": [
    "# Visualize the data and the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6480ee-c74a-462a-abeb-bffdb86213d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(BS):\n",
    "    fig, axes = plt.subplots(3,1, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    axes[0].plot(x[i,0,:].flatten(), label=\"real\")\n",
    "    if NC == 2:\n",
    "        axes[0].plot(x[i,1,:].flatten(), label=\"imaginary\")\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title(\"WITHOUT FREQUENCIES\")\n",
    "\n",
    "    axes[1].plot(kept_inds, y[i,0,:].flatten(), label=\"real\")\n",
    "    if NC == 2:\n",
    "        axes[1].plot(kept_inds, y[i,1,:].flatten(), label=\"imaginary\")\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title(\"OBSERVED MEASUREMENTS - LINEAR INTERPOLATION\")\n",
    "\n",
    "    axes[2].scatter(kept_inds, y[i,0,:].flatten(), label=\"real\")\n",
    "    if NC == 2:\n",
    "        axes[2].scatter(kept_inds, y[i,1,:].flatten(), label=\"imaginary\")\n",
    "    axes[2].legend()\n",
    "    axes[2].set_title(\"OBSERVED MEASUREMENTS\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52298a-72da-432d-aca9-0617bf2a9873",
   "metadata": {},
   "source": [
    "# Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e43437-a677-4e49-ae01-1b4d09605d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDED_LEN = 2**int(np.ceil(np.log2(LENGTH)))\n",
    "print(PADDED_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37420eb6-5616-48cf-8e87-c2ef5a4d6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFF = (PADDED_LEN - LENGTH)\n",
    "L_PAD, R_PAD = DIFF // 2, DIFF - DIFF // 2\n",
    "print(L_PAD)\n",
    "print(R_PAD)\n",
    "print(LENGTH)\n",
    "print(PADDED_LEN - L_PAD - R_PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563f646-4d8d-4cb4-84f2-da94f48434ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_inds = [k + L_PAD for k in kept_inds]\n",
    "print(len(kept_inds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97deaa90-4f89-4a5e-b0b7-f3ff3c5765c8",
   "metadata": {},
   "source": [
    "# Set up the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639473c-b788-405c-82ef-d72867f5588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DCGAN, UNET, ENC_DEC, MULTISCALE_ENC_DEC, DILATE_MULTISCALE_ENC_DEC, OS_NET\n",
    "\n",
    "# net = DCGAN(bs=BS, nz=NZ, ngf=NGF, output_size=PADDED_LEN, nc=NC)\n",
    "net = ENC_DEC(bs=BS, nz=NZ, ngf=NGF, output_size=PADDED_LEN, nc=NC)\n",
    "# net = MULTISCALE_ENC_DEC(bs=BS, nz=NZ, ngf=NGF, output_size=PADDED_LEN, nc=NC)\n",
    "# net = UNET(bs=BS, nz=NZ, ngf=NGF, output_size=PADDED_LEN, nc=NC)\n",
    "# net = DILATE_MULTISCALE_ENC_DEC(bs=BS, nz=NZ, ngf=NGF, output_size=PADDED_LEN, nc=NC)\n",
    "# net = OS_NET(bs=BS, nz=NZ, ngf=NGF, output_size=PADDED_LEN, nc=NC)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425cdbdf-d332-4c77-b39b-31714846c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = net.forward_with_z()\n",
    "print(test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37c4ba-a450-4956-be5a-2e46b549da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"TOTAL PARAMS: \", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03f511-d41a-4673-8ba1-251758816093",
   "metadata": {},
   "source": [
    "## Set up and run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9988e-fff2-4a8b-9658-4da7beac0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_wavelets import DWT1DForward\n",
    "import pywt\n",
    "\n",
    "class Wavelet_MSE_Loss(nn.Module):\n",
    "    def __init__(self, out_length, kept_inds, wavelet, alpha, device, padding=[0,0]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kept_inds = kept_inds\n",
    "        self.alpha = alpha\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss().to(device)\n",
    "        \n",
    "        w = pywt.Wavelet(wavelet)\n",
    "        maxlev = pywt.dwt_max_level(out_length, w.dec_len)\n",
    "        \n",
    "        self.dwt = DWT1DForward(J=maxlev, wave=wavelet).to(device)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        mse = self.mse_loss(x[:, :, self.kept_inds], y)\n",
    "        \n",
    "        x = x[..., self.padding[0]:-self.padding[1]]\n",
    "        wl, wh = self.dwt(x)\n",
    "        wavelet_coeffs = torch.sum(torch.abs(wl))\n",
    "        for i in range(len(wh)):\n",
    "            wavelet_coeffs += torch.sum(torch.abs(wh[i]))\n",
    "        \n",
    "        return mse + self.alpha*wavelet_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225b2a8-3be6-4022-8f40-5cd748b1d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVELET = 'sym4'\n",
    "ALPHA_REG = 1.0e-7\n",
    "\n",
    "LOSS_TYPE = \"mse\"\n",
    "\n",
    "if LOSS_TYPE==\"mse\":\n",
    "    criterion = lambda x, y: nn.MSELoss()(x[:, :, kept_inds], y)\n",
    "elif LOSS_TYPE==\"mse_wavelet\":\n",
    "    criterion = Wavelet_MSE_Loss(LENGTH, kept_inds, WAVELET, ALPHA_REG, device, padding=[L_PAD, R_PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431267e-6e2d-4a40-9862-58b94c4dd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.train()\n",
    "\n",
    "optim = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "train_losses = []\n",
    "test_mses = []\n",
    "test_maes = []\n",
    "outputs = []\n",
    "\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f89c6e-a524-4f1f-aeef-2d9f383bea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "for i in range(NUM_ITER):\n",
    "    net.perturb_noise(0.05) \n",
    "    \n",
    "    optim.zero_grad()\n",
    "    \n",
    "    out = net.forward_with_z()\n",
    "    train_loss = criterion(out, y)\n",
    "    \n",
    "    train_loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = out[..., L_PAD:-R_PAD]\n",
    "        \n",
    "        outputs.append(out.detach().clone().cpu())\n",
    "        train_losses.append(train_loss.item())\n",
    "        \n",
    "        test_mse = nn.MSELoss()(out, x)\n",
    "        test_mses.append(test_mse.item())\n",
    "        \n",
    "        test_mae = nn.L1Loss()(out, x)\n",
    "        test_maes.append(test_mae.item())\n",
    "\n",
    "        if (i+1)%100 == 0 or i == 0:\n",
    "            toc = time.time()\n",
    "            print(\"ITER \", str(i))\n",
    "            print(\"TIME: \", str(toc - tic))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf78913-e147-40ce-a7df-fdcc83f92fcd",
   "metadata": {},
   "source": [
    "## Plot the final and best outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4685f-2321-4fa3-b3a2-13ec2cd63a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_last = outputs[-1]\n",
    "\n",
    "for i in range(BS):\n",
    "    fig, axes = plt.subplots(NC+2,1, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    axes[0].plot(x[i,0,:].flatten().detach().cpu(), label=\"real\")\n",
    "    if NC == 2:\n",
    "        axes[0].plot(x[i,1,:].flatten().detach().cpu(), label=\"imaginary\")\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title(\"TRUE\")\n",
    "\n",
    "    axes[1].plot(out_last[i,0,:].flatten().detach().cpu(), label=\"real\")\n",
    "    if NC == 2:\n",
    "        axes[1].plot(out_last[i,1,:].flatten().detach().cpu(), label=\"imaginary\")\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title(\"LAST NET OUTPUT\")\n",
    "\n",
    "    axes[2].plot(x[i,0,:].flatten().detach().cpu(), label=\"Actual\")\n",
    "    axes[2].plot(out_last[i,0,:].flatten().detach().cpu(), label=\"Last Net Output\")\n",
    "    axes[2].legend()\n",
    "    axes[2].set_title(\"REALS\")\n",
    "\n",
    "    if NC == 2:\n",
    "        axes[3].plot(x[i,1,:].flatten().detach().cpu(), label=\"Actual\")\n",
    "        axes[3].plot(out_last[i,1,:].flatten().detach().cpu(), label=\"Last Net Output\")\n",
    "        axes[3].legend()\n",
    "        axes[3].set_title(\"IMAGINARY\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cc88e-3bed-4d9f-a38a-e8fe174782e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_best = outputs[np.argmin(train_losses)]\n",
    "print(\"BEST TRAIN ITER: \", np.argmin(train_losses))\n",
    "\n",
    "for i in range(BS):\n",
    "    fig, axes = plt.subplots(NC+2,1, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    axes[0].plot(x[i,0,:].flatten().detach().cpu(), label=\"real\")\n",
    "    if NC == 2:\n",
    "        axes[0].plot(x[i,1,:].flatten().detach().cpu(), label=\"imaginary\")\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title(\"TRUE\")\n",
    "\n",
    "    axes[1].plot(out_best[i,0,:].flatten().detach().cpu(), label=\"real\")\n",
    "    if NC == 2:\n",
    "        axes[1].plot(out_best[i,1,:].flatten().detach().cpu(), label=\"imaginary\")\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title(\"BEST NET OUTPUT\")\n",
    "\n",
    "    axes[2].plot(x[i,0,:].flatten().detach().cpu(), label=\"Actual\")\n",
    "    axes[2].plot(out_best[i,0,:].flatten().detach().cpu(), label=\"Best Net Output\")\n",
    "    axes[2].legend()\n",
    "    axes[2].set_title(\"REALS\")\n",
    "\n",
    "    if NC == 2:\n",
    "        axes[3].plot(x[i,1,:].flatten().detach().cpu(), label=\"Actual\")\n",
    "        axes[3].plot(out_best[i,1,:].flatten().detach().cpu(), label=\"Best Net Output\")\n",
    "        axes[3].legend()\n",
    "        axes[3].set_title(\"IMAGINARY\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b7509-5424-414f-8016-64ce9a18b7b3",
   "metadata": {},
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f7c73-48f8-4615-8190-0990e55bf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = 100\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"TRAIN LOSS\")\n",
    "plt.ylim(0., train_losses[max_idx])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_mses, color='r')\n",
    "plt.title(\"MSE\")\n",
    "plt.ylim(0., test_mses[max_idx])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_maes, color='g')\n",
    "plt.title(\"MAE\")\n",
    "plt.ylim(0, test_maes[max_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23228dde-6b07-4cc5-9b46-cb86ef6003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal \n",
    "\n",
    "#prepare for numpy operations\n",
    "x_np = x.detach().cpu().numpy()\n",
    "outputs_np = torch.cat(outputs, dim=0)\n",
    "outputs_np = outputs_np.detach().cpu().numpy()\n",
    "\n",
    "#resample if the signal is too large!\n",
    "RESAMPLE_LEN = 1000\n",
    "if LENGTH > RESAMPLE_LEN:\n",
    "    outputs_np = scipy.signal.decimate(outputs_np, int(np.ceil(LENGTH / RESAMPLE_LEN)),ftype='fir', axis=-1)\n",
    "    x_np = scipy.signal.decimate(x_np, int(np.ceil(LENGTH / RESAMPLE_LEN)), ftype='fir', axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ce21b-b1b6-4eb8-913d-928c8d556463",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_np.shape)\n",
    "print(outputs_np.shape)\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(x_np[0,0,:])\n",
    "plt.title(\"RESAMPLED OG\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(outputs_np[np.argmin(train_losses),0,:])\n",
    "plt.title(\"RESAMPLED BEST DIP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16a35e-af30-425c-8b56-b2373e2452a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import *\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "dtw_list_re = []\n",
    "if NC == 2:\n",
    "    dtw_list_im = []\n",
    "    \n",
    "for i in range(outputs_np.shape[0]):\n",
    "    sig = outputs_np[i]\n",
    "    \n",
    "    l_dtw_re = dtw(x_np[0,0,:].flatten(), sig[0,:].flatten(), distance_only=True)\n",
    "    dtw_list_re.append(l_dtw_re.distance)\n",
    "    if NC == 2:\n",
    "        l_dtw_im = dtw(x_np[0,1,:].flatten(), sig[1,:].flatten(), distance_only=True)\n",
    "        dtw_list_im.append(l_dtw_im.distance)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"TIME: \", str(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13642a66-bc66-46d6-8475-a433c9d7a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(dtw_list_re, color='m')\n",
    "plt.title(\"DTW REAL\")\n",
    "plt.ylim(0, dtw_list_re[max_idx])\n",
    "plt.show()\n",
    "\n",
    "if NC == 2:\n",
    "    plt.figure()\n",
    "    plt.plot(dtw_list_im)\n",
    "    plt.title(\"DTW IMAGINARY\")\n",
    "    plt.ylim(0, dtw_list_im[max_idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82568359-08c3-430b-ba74-99e35bdfaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEST TRAIN LOSS (IDX, VAL): \", np.argmin(train_losses), np.min(train_losses))\n",
    "print(\"LAST TRAIN LOSS (VAL): \", train_losses[-1])\n",
    "print()\n",
    "\n",
    "print(\"BEST MSE (IDX, VAL): \", np.argmin(test_mses), np.min(test_mses))\n",
    "print(\"LAST MSE (VAL): \", test_mses[-1])\n",
    "print(\"TRAIN BEST MSE (VAL): \", test_mses[np.argmin(train_losses)])\n",
    "print()\n",
    "\n",
    "print(\"BEST MAE (IDX, VAL): \", np.argmin(test_maes), np.min(test_maes))\n",
    "print(\"LAST MAE (VAL): \", test_maes[-1])\n",
    "print(\"TRAIN BEST MAE (VAL): \", test_maes[np.argmin(train_losses)])\n",
    "print()\n",
    "\n",
    "print(\"BEST REAL DTW (IDX, VAL): \", np.argmin(dtw_list_re), np.min(dtw_list_re))\n",
    "print(\"LAST REAL DTW (VAL): \", dtw_list_re[-1])\n",
    "print(\"TRAIN BEST REAL DTW (VAL): \", dtw_list_re[np.argmin(train_losses)])\n",
    "print()\n",
    "\n",
    "if NC==2:\n",
    "    print(\"BEST IM DTW (IDX, VAL): \", np.argmin(dtw_list_im), np.min(dtw_list_im))\n",
    "    print(\"LAST IM DTW (VAL): \", dtw_list_im[-1])\n",
    "    print(\"TRAIN BEST IM DTW (VAL): \", dtw_list_im[np.argmin(train_losses)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1c781-0bc3-4d38-9f7d-357c37e218e5",
   "metadata": {},
   "source": [
    "## Calculate the linear interpolation for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798d5a3-afb1-4359-8e1a-8160f8d156c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make kept_inds the original value\n",
    "kept_inds = [k - L_PAD for k in kept_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97acfb2d-2fc6-4334-afbf-704189eb9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_re = np.interp(np.arange(LENGTH), kept_inds, y[0,0,:].detach().cpu().flatten())\n",
    "if NC == 2:\n",
    "    x_int_im = np.interp(np.arange(LENGTH), kept_inds, y[0,1,:].detach().cpu().flatten())\n",
    "\n",
    "figsize=(6,3)\n",
    "    \n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(x_int_re, label=\"Interpolation\")\n",
    "plt.plot(x[0,0,:].detach().cpu(), label=\"Real\")\n",
    "plt.legend()\n",
    "plt.title(\"Linear interpolation vs Real\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(x[0,0,:].detach().cpu() - x_int_re)\n",
    "plt.title(\"Real minus Linear Interpolation\")\n",
    "plt.show()\n",
    "\n",
    "if NC == 2:\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(x_int_im, label=\"Interpolation\")\n",
    "    plt.plot(x[0,1,:].detach().cpu(), label=\"Imaginary\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Linear interpolation vs Imaginary\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(x[0,1,:].detach().cpu() - x_int_im)\n",
    "    plt.title(\"Imaginary minus Linear Interpolation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343ca01-cfa5-4bd5-83da-0bc630813d89",
   "metadata": {},
   "source": [
    "## MSE Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb83cd-b1a7-4410-a7bb-e9259a222247",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NC == 2:\n",
    "    sse_re = nn.MSELoss(reduction=\"sum\")(torch.tensor(x_int_re), x[0,0,:].detach().cpu())\n",
    "    sse_im = nn.MSELoss(reduction=\"sum\")(torch.tensor(x_int_im), x[0,1,:].detach().cpu())\n",
    "    mse_tot = (sse_re + sse_im) / (2*LENGTH)\n",
    "else:\n",
    "    sse_re = nn.MSELoss(reduction=\"sum\")(torch.tensor(x_int_re), x[0,0,:].detach().cpu())\n",
    "    mse_tot = sse_re / LENGTH\n",
    "\n",
    "print(\"LINEAR INTERPOLATION MSE: \", mse_tot.item())\n",
    "print(\"DIP MSE (LAST): \", test_mses[-1])\n",
    "print(\"DIP MSE (BEST): \", np.min(test_mses))\n",
    "print(\"DIP MSE (TRAIN BEST): \", test_mses[np.argmin(train_losses)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019df5c5-c626-44e9-bfe7-0e1a2cc4cc30",
   "metadata": {},
   "source": [
    "## DTW Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d40374-af23-4760-b18e-b1357548fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_last_re = dtw(outputs[-1][0,0,:].flatten().detach().cpu().numpy(), x[0,0,:].flatten().detach().cpu().numpy(), distance_only=True)\n",
    "dtw_train_best_re = dtw(outputs[np.argmin(train_losses)][0,0,:].flatten().detach().cpu().numpy(), x[0,0,:].flatten().detach().cpu().numpy(), distance_only=True)\n",
    "\n",
    "if NC == 2:\n",
    "    dtw_last_im = dtw(outputs[-1][0,1,:].flatten().detach().cpu().numpy(), x[0,1,:].flatten().detach().cpu().numpy(), distance_only=True)\n",
    "    dtw_train_best_im = dtw(outputs[np.argmin(train_losses)][0,1,:].flatten().detach().cpu().numpy(), x[0,1,:].flatten().detach().cpu().numpy(), distance_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf24435-582c-4533-bfe7-85217316d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_dtw = dtw(x[0,0,:].detach().cpu().numpy(), x_int_re, distance_only=True)\n",
    "print(\"DTW(INTERPOLATION, REAL)\", l_dtw.distance)\n",
    "\n",
    "print(\"DTW(DIP, REAL) (LAST)\", dtw_last_re.distance)\n",
    "print(\"DTW(DIP, REAL) (TRAIN BEST)\", dtw_train_best_re.distance)\n",
    "\n",
    "if NC == 2:\n",
    "    print()\n",
    "    \n",
    "    l_dtw = dtw(x[0,1,:].detach().cpu().numpy(), x_int_im, distance_only=True)\n",
    "    print(\"DTW(INTERPOLATION, IMAGINARY)\", l_dtw.distance)\n",
    "    \n",
    "    print(\"DTW(DIP, IM) (LAST)\", dtw_last_im.distance)\n",
    "    print(\"DTW(DIP, IM) (TRAIN BEST)\", dtw_train_best_im.distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a354e9-4477-4351-8a66-16e60e3618e4",
   "metadata": {},
   "source": [
    "## MAE (L1 Error) Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687d6c5-c51b-48f4-b697-fe1dc947853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NC == 2:\n",
    "    mae_re = nn.L1Loss(reduction=\"sum\")(torch.tensor(x_int_re), x[0,0,:].detach().cpu())\n",
    "    mae_im = nn.L1Loss(reduction=\"sum\")(torch.tensor(x_int_im), x[0,1,:].detach().cpu())\n",
    "    mae_tot = (mae_re + mae_im) / (2*LENGTH)\n",
    "else:\n",
    "    mae_re = nn.L1Loss(reduction=\"sum\")(torch.tensor(x_int_re), x[0,0,:].detach().cpu())\n",
    "    mae_tot = mae_re / LENGTH\n",
    "\n",
    "print(\"LINEAR INTERPOLATION MAE: \", mae_tot.item())\n",
    "print(\"DIP MAE (LAST): \", test_maes[-1])\n",
    "print(\"DIP MAE (BEST): \", np.min(test_maes))\n",
    "print(\"DIP MAE (TRAIN BEST): \", test_maes[np.argmin(train_losses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f35ffb-db06-4308-a821-64d81de4db72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
