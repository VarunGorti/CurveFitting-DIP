{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch1/04703/sravula/venvs/basic/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from AFSParser import build_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4 # learning rate\n",
    "MOM = 0.9 # momentum\n",
    "NUM_ITER = 10001 # number iterations\n",
    "WD = 1e-4 # weight decay for l2-regularization\n",
    "TV = 1e-2 # total variation regularisation \n",
    "\n",
    "Z_NUM = 32 # input seed dimension\n",
    "NGF = 64 # number of filters per layer\n",
    "NC = 1 # number of channels\n",
    "\n",
    "GIVEN_MEASUREMENTS = 5 # inverse of proportion of given measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the file\n",
    "X, y0 = build_dataset(True, \"/scratch1/04703/sravula/UTAFSDataNew\")\n",
    "\n",
    "# Choose an s4p example from the dataset (arbitrarily choose the first for now)\n",
    "X, y0 = torch.from_numpy(X[0]).float(), y0[0]\n",
    "LENGTH = len(X) # number of frequency samples for this s4p chip\n",
    "NUM_MEASUREMENTS = math.ceil(LENGTH / GIVEN_MEASUREMENTS)\n",
    "# kept_samples = range(NUM_MEASUREMENTS)\n",
    "kept_samples = range(0, LENGTH, NUM_MEASUREMENTS)\n",
    "imputed_samples = [x for x in range(LENGTH) if x not in kept_samples]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize then graph the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Think about what type of normalization is happening here\n",
    "def normalise(x):\n",
    "    y = np.squeeze(x)\n",
    "    \n",
    "    mins = np.min(y)\n",
    "    maxs = np.max(y)\n",
    "    ranges = maxs - mins\n",
    "    \n",
    "    return (x - mins)/ranges\n",
    "\n",
    "y_normalized = np.zeros_like(y0)\n",
    "# Normalize all of the curves separately\n",
    "for i in range(10):\n",
    "    y_normalized[:, i, 0] = normalise(y0[:, i, 0])\n",
    "    y_normalized[:, i, 1] = normalise(y0[:, i, 1])\n",
    "\n",
    "\n",
    "figure, axis = plt.subplots(10, 2, figsize=(100, 100))\n",
    "for i in range(10):\n",
    "    axis[i, 0].plot(X, y_normalized[:, i, 0]) # The reals for the i'th s-parameter\n",
    "    axis[i, 0].set_title(\"s-param \" + str(i) + \" reals\")\n",
    "    axis[i, 1].plot(X, y_normalized[:, i, 1]) # The reals for the i'th s-parameter\n",
    "    axis[i, 1].set_title(\"s-param \" + str(i) + \" imag\")\n",
    "plt.show()\n",
    "\n",
    "# For now, just focus on the REAL values of ONE of the s-params for this chip\n",
    "y_normalized = y_normalized[:, 0, 0]\n",
    "\n",
    "meas = y_normalized[kept_samples]\n",
    "y = torch.from_numpy(meas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Train a model to learn on one curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the network: (currently using default model from 1D-DIP example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(nn.Module):\n",
    "    def __init__(self, nz, ngf=64, output_size=1024, nc=1, num_measurements=64):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.output_size = output_size\n",
    "        self.num_measurements = num_measurements\n",
    "\n",
    "        # Deconv Layers: (in_channels, out_channels, kernel_size, stride, padding, bias = false)\n",
    "        # Inputs: R^(N x Cin x Lin), Outputs: R^(N, Cout, Lout) s.t. Lout = (Lin - 1)*stride - 2*padding + kernel_size\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose1d(nz, ngf, 4, 1, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 1: input: (random) zϵR^(nzx1), output: x1ϵR^(64x4) (channels x length)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 2: input: x1ϵR^(64x4), output: x2ϵR^(64x8) (channels x length)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 3: input: x2ϵR^(64x8), output: x3ϵR^(64x16) (channels x length)\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn4 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 4: input: x3ϵR^(64x16), output: x4ϵR^(64x32) (channels x length)\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn5 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 5: input: x4ϵR^(64x32), output: x5ϵR^(64x64) (channels x length)\n",
    "\n",
    "        self.conv6 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn6 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 6: input: x5ϵR^(64x64), output: x6ϵR^(64x128) (channels x length)\n",
    "        \n",
    "        self.conv7 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn7 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 7: input: x6ϵR^(64x128), output: x7ϵR^(64x256) (channels x length)\n",
    "\n",
    "        self.conv8 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn8 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 8: input: x7ϵR^(64x256), output: x8ϵR^(64x512) (channels x length)\n",
    "\n",
    "        self.conv9 = nn.ConvTranspose1d(ngf, nc, 4, 2, 1, bias=False)  # output is image\n",
    "        # LAYER 9: input: x8ϵR^(64x512), output: G(z,w)ϵR^(1x1024) (channels x length)\n",
    "        # Deconv Layers: (in_channels, out_channels, kernel_size, stride, padding, bias = false)\n",
    "        # Inputs: R^(N x Cin x Lin), Outputs: R^(N, Cout, Lout) s.t. Lout = (Lin - 1)*stride - 2*padding + kernel_size\n",
    "\n",
    "        self.output = nn.Linear(1024, output_size * nc, bias=False)\n",
    "        # TODO: LAYER 10: not too sure about this, currently taking the output of layer 9 and using linear layer to get correct shape\n",
    "\n",
    "        self.fc = nn.Linear(output_size * nc, num_measurements, bias=False)  # output is A; measurement matrix\n",
    "        # each entry should be drawn from a Gaussian (random noisy measurements)\n",
    "        # don't compute gradient of self.fc! memory issues\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"INPUT\", x.shape)\n",
    "        # x = self.conv1(x)\n",
    "        # print(\"Post conv\", x.shape)\n",
    "        # x = F.relu(self.bn1(x))\n",
    "        # print(\"Post batch norm\", x.shape)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.sigmoid(self.output(x)) # Get the output size to match the curve length we expect\n",
    "\n",
    "        return x\n",
    "\n",
    "    def measurements(self, x):\n",
    "        # this gives the image - make it a single row vector of appropriate length\n",
    "        y = self.forward(x).view(1, -1)\n",
    "\n",
    "        # pass thru FC layer - returns A*image\n",
    "        meas = self.fc(y).view(-1, 1)\n",
    "\n",
    "        if CUDA:\n",
    "            return meas.cuda()\n",
    "        else:\n",
    "            return meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z_NUM, NGF, LENGTH, NC, NUM_MEASUREMENTS)\n",
    "net = DCGAN(Z_NUM, NGF, LENGTH, NC, NUM_MEASUREMENTS)\n",
    "\n",
    "net.fc.weight.data = torch.eye(LENGTH)[kept_samples]\n",
    "net.fc.requires_grad = False\n",
    "\n",
    "if CUDA: # move network to GPU if available\n",
    "    net = net.cuda()\n",
    "\n",
    "# Define input seed z as Torch variable, fill with random normal data\n",
    "z = torch.zeros(Z_NUM).type(dtype).view(1, Z_NUM, 1)\n",
    "z.data.normal_().type(dtype)\n",
    "z._requires_grad()\n",
    "\n",
    "allparams = [x for x in net.parameters()] #specifies which to compute gradients of\n",
    "allparams = allparams[:-1] # get rid of last item in list (fc layer) because it's memory intensive\n",
    "allparams.extend(z)\n",
    "\n",
    "optim = torch.optim.RMSprop(allparams,lr=LR,momentum=MOM, weight_decay=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_TV_LOSS(pred, net_meas, y, alpha_TV, dtype):\n",
    "    TV = torch.sum(torch.abs(pred[:-1, :] - pred[1:, :]))\n",
    "\n",
    "    mse = torch.nn.MSELoss(reduction='sum').type(dtype)\n",
    "    MSE = mse(net_meas, y)\n",
    "\n",
    "    return MSE + alpha_TV * TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_log_train = np.zeros((NUM_ITER)) #The entire network prediction vs the known measurements\n",
    "mse_log_test = np.zeros((NUM_ITER)) #The network prediction vs true signal ONLY at unknown values\n",
    "net_output = np.zeros(LENGTH)\n",
    "\n",
    "curve = np.zeros((LENGTH, 1))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(NUM_ITER):\n",
    "\n",
    "    optim.zero_grad() # clears graidents of all optimized variables\n",
    "    out = net(z) # produces curve (in form of data tensor) i.e. G(z,w)\n",
    "    \n",
    "    # print(\"Z shape:\", z.shape)\n",
    "    # print(\"out shape:\", out.shape)\n",
    "    # print(\"net.measurements(z) shape:\", net.measurements(z).shape)\n",
    "    # print(\"y shape:\", y.shape)\n",
    "\n",
    "    loss = MSE_TV_LOSS(out.view(-1,1), np.squeeze(net.measurements(z)), y, TV, dtype) # calculate loss between AG(z,w) and Ay\n",
    "    \"\"\"\n",
    "    wzeros = torch.zeros(out.size())\n",
    "    if CUDA:\n",
    "        wzeros = wzeros.cuda()\n",
    "    out_full = torch.stack((out, wzeros), dim=3)\n",
    "    fft_out = torch.fft(out_full, signal_ndim=1, normalized=False)\n",
    "    weight_l1_norm = torch.norm(fft_out, p=1)\n",
    "    loss = loss + reg_lambda*weight_l1_norm\n",
    "    \"\"\"\n",
    "    \n",
    "    curve[:,0] = out.data[0].cpu()[0,:] #transfer network output back to cpu to visualize and compare performance\n",
    "\n",
    "    mse_log_train[i] = np.mean((curve[kept_samples] - meas)**2)\n",
    "    mse_log_test[i] = np.mean((curve[imputed_samples] - y_normalized[imputed_samples])**2)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "        plt.plot(np.arange(LENGTH), curve, label=\"Network Output\")\n",
    "        plt.plot(np.arange(LENGTH), y_normalized, color='r', label = \"True Signal\")\n",
    "        plt.xlabel(\"Sample\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.title(\"Network Prediction vs True Signal\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    if i == NUM_ITER - 1:\n",
    "        net_output = curve.squeeze()\n",
    "    \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution Time: \", round(end-start, 2), \"s\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ccf9f24fb63ed59c236fd10a93cb8b545ca3a39e47263b99763c8981aafa253"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
